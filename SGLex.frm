// ==>ModuleName.cs                                              HDO, 2006-08-28
// -------------
// Lexical analyzer (finite-state machine interpreter).
// Generated by Coco-2 (SG).
//=====================================|========================================

#undef TEST_Lex

using System;
using System.Collections;
using System.Collections.Specialized;
using System.IO;
using System.Text;

public class ==>ModuleName {

  public const String MODULENAME = "==>ModuleName";
  public const int    EOFSPIX    = 1;

  public static TextReader src;

  // --- token information ---
  public static int    token;               // current token
  public static int    tokenLine, tokenCol; // position of current token
  public static String tokenStr;            // token string recognized

  // --- current char. info, for "power users" only ---
  public static char   curCh;               // current input character
  public static int    curLine, curCol;     // position of curCh


  public static void ==>ModuleNameMethod(Utils.ModuleAction action, out String moduleName) {
  //-----------------------------------|----------------------------------------
    moduleName = MODULENAME;
    switch (action) {
      case Utils.ModuleAction.getModuleName:
        return;
      case Utils.ModuleAction.initModule:
        caseSensitive = ==>CaseSensitivity;
        lt            = new LexicalTable();
        tokenStrArr   = new char[256];
        kwHt          = CreateHashtable();
        nHt           = CreateHashtable();
        nl            = new ArrayList();
        break;
      case Utils.ModuleAction.resetModule:
        kwHt.Clear();
        nHt.Clear();
        nl.Clear();
        break;
      case Utils.ModuleAction.cleanupModule:
        lt            = null;
        tokenStrArr   = null;
        kwHt          = null;
        nHt           = null;
        nl            = null;
        break;
    } // switch
  } // ==>ModuleNameMethod

  private static  Hashtable CreateHashtable() {
    if (caseSensitive)
      return new Hashtable();
    else
      return CollectionsUtil.CreateCaseInsensitiveHashtable();
  } // CreateHashtable


  public static void InitLex() {
  //-----------------------------------|----------------------------------------
    // --- initialize keyword hash table  ---
    kwHt.Clear();
    ==>Initialisations
    // --- initialize name data structures  ---
    nHt.Clear();
    nl.Clear();
    nl.Add("");      // so spix = 0 is the empty string
    nl.Add("!EOF!"); // so EOFSPIX = 1
    // --- (re)set global data ---
    curLineStr  = "";
    curCh       = ' ';
    curLine     = 0;
    curCol      = 2;
    tokenStr    = null;
    token       = 0;
    tokenCol    = 0;
    tokenLine   = 0;
    tokenStrLen = 0;
    pendingEOLs = 0;
    apxLen      = pendingEOLs; // to prevent warning
  } // InitLex

  private static void EnterKeyword(int token, String keyword) {
    kwHt.Add(keyword, token);
  } // EnterKeyword


  // *** start of global LEX declarations from ATG ***
  ==>GlobalDeclarations
  // *** end of global LEX declarations from ATG ***


  public static bool caseSensitive;

  private class LexicalTable {
    public int   header = ==>header;
    public int[] startTab = {
        ==>startTab
      };
    public Sets.Set256 ignoredChars = new Sets.Set256(
        ==>ignoredChars
      );
    public Sets.Set256 commentStart = new Sets.Set256(
        ==>commentStart
      );
    public Sets.Set256[] cls = {
        ==>cls
      };
  } // LexicalTable

  private static LexicalTable lt;
  private static Hashtable    kwHt;  // hash table for keywords: string -> token 
  private static Hashtable    nHt;   // hash table for names: string -> null 
  private static ArrayList    nl;    // name list  for names, index is spix

  private static String curLineStr;  // current source line
  private static char[] tokenStrArr; // token string in an array
  private static int    tokenStrLen; // length of token string in tokenStrArr
  private static int    state;       // current automaton state
  private static int    apxLen;      // length of appendix in token string
  private static int    pendingEOLs; // nr of EOLs found in comment

  // --- to save and restore scanner state ---
  private static char   savedCh;
  private static int    savedCol, savedLine;

  private static void SaveScannerState() {
    savedCh      = curCh;
    savedCol     = curCol;
    savedLine    = curLine;
  } // SaveScannerState

  private static void RestoreScannerState() {
    tokenStrLen -= apxLen;
    apxLen       = 0;
    curCh        = savedCh;
    curCol       = savedCol;
    curLine      = savedLine;
  } // RestoreScannerState


  public static void NextCh() {
  //-----------------------------------|----------------------------------------
    for (;;) {
      ==>NextChMethodFront
      if (curCol < curLineStr.Length) {         // within line
        curCol++;
        curCh = curLineStr[curCol - 1];
        return;
      } else if (curCol == curLineStr.Length) { // end of line
        curCol++;
        curCh = Utils.LF; // to separate lines
        return;
      } else { // curCol > curLineStr.Length
        curLineStr = src.ReadLine();
        curLine++;
        curCol = 0;
        if (curLineStr == null) {               // end of file
          curLineStr = "";
          curCh = Utils.EF;
          return;
        } // if
      } // else
    } // for
  } // NextCh


  private static void CommentErr() {
    Errors.LexError(curLine, curCol, "end of file in comment");
  } // CommentErr

  private static bool Comment() {
    ==>CommentMethod
    return false;
  } // Comment

  private static void HandleLexErr() {
    Errors.LexError(curLine, curCol, 
                    "invalid character '{0}' (hex {1:X})", curCh, (int)curCh);
    if (apxLen > 0)
      RestoreScannerState();
  } // HandleLexErr


  public static void GetToken() {
  //-----------------------------------|----------------------------------------
    token = -1;
    tokenStr = null;
    do {
      ==>GetTokenMethodFront
      // --- scan for next token ---
      tokenLine   = curLine;
      tokenCol    = curCol;
      tokenStrLen = 0;
      apxLen      = 0;
      state = (curCh == Utils.EF) ? 1 : lt.startTab[curCh];
      for (;;) {
        tokenStrArr[tokenStrLen++]= curCh;
        NextCh();
        switch (state) {
          case 0:
            Errors.LexError(tokenLine, tokenCol, "invalid token start");
            break;
          case 1:
            token = 0;
            tokenStrLen = 0;
            break;                      // EOF recognized
          ==>GetTokenMethodCaseBody
        } // switch
        break;
      } // for
    } while (token < 0);
    if (tokenStr == null)
      tokenStr = new String(tokenStrArr, 0, tokenStrLen);
  } // GetToken

  private static int KeywordCheck() {
    tokenStr = new String(tokenStrArr, 0, tokenStrLen - apxLen);
    Object token = kwHt[tokenStr];
    return (token == null) ? -1 : (int)token;
  } // KeywordCheck


  public static int Hash(String s) {
  //-----------------------------------|----------------------------------------
    Object spix = nHt[s];
    if (spix == null) {
      if (caseSensitive)
        nl.Add(s);
      else
        nl.Add(s.ToUpper());
      spix   = nl.Count - 1;
      nHt[s] = spix;
    } // if
    return (int)spix;
  } // Hash
  
  
  public static String HashedStr(int spix) {
  //-----------------------------------|----------------------------------------
    return (String)nl[spix];
  } // HashedStr


  ==>TokenClass&PragmaMethodsImpls

} // ==>ModuleName

// End of ==>ModuleName.cs
//=====================================|========================================
